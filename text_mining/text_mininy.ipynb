{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Preditiva de Satisfação Aérea: Abordagem Híbrida\n",
    "\n",
    "**Contexto:** Este projeto visa classificar a satisfação de passageiros de companhias aéreas.\n",
    "\n",
    "**Estratégia:** Compararemos três abordagens de modelagem:\n",
    "1. **Dados Tabulares:** Utilizando apenas notas numéricas e categorias.\n",
    "2. **Processamento de Linguagem Natural (NLP):** Utilizando apenas o texto dos reviews.\n",
    "3. **Híbrida:** Combinando dados estruturados e não estruturados para maximizar a performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente e Carga de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configurações visuais\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Correção para download do NLTK em ambientes com SSL restrito\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "print(\"Inicializando download de recursos NLTK...\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "print(\"Ambiente pronto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('airlines_reviews.csv')\n",
    "    print(f\"Base carregada com sucesso: {df.shape[0]} registros e {df.shape[1]} colunas.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro crítico: O arquivo 'airlines_reviews.csv' não foi encontrado no diretório.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória de Dados (EDA)\n",
    "Verificação da integridade dos dados, distribuição da variável alvo e correlações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de integridade\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"Integridade dos dados: OK (Nenhum valor nulo encontrado).\")\n",
    "else:\n",
    "    print(\"Valores nulos encontrados:\")\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do Target\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x='Recommended', data=df, palette='viridis')\n",
    "plt.title('Balanceamento das Classes (Target: Recommended)', fontsize=14)\n",
    "\n",
    "total = len(df)\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "    x = p.get_x() + p.get_width()/2\n",
    "    y = p.get_height()\n",
    "    ax.annotate(percentage, (x, y), ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação (apenas numéricas)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlação entre Variáveis Numéricas', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engenharia de Features e Pré-processamento\n",
    "Nesta etapa, convertemos o alvo para binário, removemos colunas que não agregam valor preditivo e aplicamos técnicas de NLP nos comentários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transformação do Target\n",
    "df['target'] = df['Recommended'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 2. Remoção de Colunas Irrelevantes ou Vazadas (Data Leakage)\n",
    "cols_to_drop = ['Name', 'Title', 'Route', 'Review Date', 'Month Flown', 'Recommended', 'Verified']\n",
    "\n",
    "# Removemos 'Overall Rating' se existir, pois tem correlação quase perfeita com o target (vazamento)\n",
    "if 'Overall Rating' in df.columns:\n",
    "    cols_to_drop.append('Overall Rating')\n",
    "\n",
    "df_clean = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# 3. Encoding da Classe do Voo (Ordinal)\n",
    "class_map = {\n",
    "    'Economy Class': 0,\n",
    "    'Premium Economy': 1,\n",
    "    'Business Class': 2,\n",
    "    'First Class': 3\n",
    "}\n",
    "df_clean['Class_Encoded'] = df_clean['Class'].map(class_map)\n",
    "df_clean.drop('Class', axis=1, inplace=True)\n",
    "\n",
    "print(\"Estrutura tabular finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text_pipeline(text):\n",
    "    \"\"\"\n",
    "    Pipeline de limpeza: lowercase -> regex (apenas letras) -> stopwords -> lematização\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) \n",
    "    words = text.split()\n",
    "    # Mantém palavras que não são stopwords e têm mais de 2 letras\n",
    "    cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "print(\"Executando pipeline de NLP nos reviews...\")\n",
    "df_clean['Reviews_Clean'] = df_clean['Reviews'].apply(clean_text_pipeline)\n",
    "\n",
    "print(\"Exemplo de processamento:\")\n",
    "print(f\"ORIGINAL: {df['Reviews'].iloc[0][:60]}...\")\n",
    "print(f\"LIMPO:    {df_clean['Reviews_Clean'].iloc[0][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão Treino / Teste (Estratificada para manter o balanceamento)\n",
    "X = df_clean.drop(['target'], axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Dimensões - Treino: {X_train.shape}, Teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento e Avaliação de Modelos\n",
    "Serão avaliados três cenários para determinar a importância das features textuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Definição das colunas\n",
    "numeric_features = ['Seat Comfort', 'Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Value For Money', 'Class_Encoded']\n",
    "categorical_features = ['Airline', 'Type of Traveller']\n",
    "text_feature = 'Reviews_Clean'\n",
    "\n",
    "# Preprocessor para dados estruturados\n",
    "tabular_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. Treinando Modelo Tabular (Random Forest)...\")\n",
    "model_tabular = Pipeline(steps=[\n",
    "    ('preprocessor', tabular_preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model_tabular.fit(X_train, y_train)\n",
    "y_pred_tab = model_tabular.predict(X_test)\n",
    "acc_tab = accuracy_score(y_test, y_pred_tab)\n",
    "results['Tabular'] = acc_tab\n",
    "print(f\"> Acurácia: {acc_tab:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2. Treinando Modelo Textual (TF-IDF + Regressão Logística)...\")\n",
    "model_text = Pipeline(steps=[\n",
    "    ('vectorizer', TfidfVectorizer(max_features=3000)),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "model_text.fit(X_train[text_feature], y_train)\n",
    "y_pred_text = model_text.predict(X_test[text_feature])\n",
    "acc_text = accuracy_score(y_test, y_pred_text)\n",
    "results['Text'] = acc_text\n",
    "print(f\"> Acurácia: {acc_text:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3. Treinando Modelo Híbrido (Features Tabulares + Texto)...\")\n",
    "\n",
    "# Combinação de transformadores\n",
    "hybrid_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('text', TfidfVectorizer(max_features=3000), text_feature)\n",
    "    ])\n",
    "\n",
    "model_hybrid = Pipeline(steps=[\n",
    "    ('preprocessor', hybrid_preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model_hybrid.fit(X_train, y_train)\n",
    "y_pred_hybrid = model_hybrid.predict(X_test)\n",
    "acc_hybrid = accuracy_score(y_test, y_pred_hybrid)\n",
    "results['Hybrid'] = acc_hybrid\n",
    "print(f\"> Acurácia: {acc_hybrid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Resultados e Relatório Executivo\n",
    "Interpretação dos dados para entender o que motiva a recomendação do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"RESUMO DE PERFORMANCE DOS MODELOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ordenar resultados\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for model_name, acc in sorted_results:\n",
    "    print(f\"Modelo {model_name}: {acc*100:.2f}% de Acurácia\")\n",
    "\n",
    "best_model = sorted_results[0]\n",
    "worst_model = sorted_results[-1]\n",
    "improvement = (best_model[1] - worst_model[1]) * 100\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"CONCLUSÃO: O modelo '{best_model[0]}' obteve o melhor desempenho.\")\n",
    "print(f\"Diferença de performance entre o melhor e o pior: {improvement:.2f} p.p.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de Feature Importance (Baseada no modelo textual linear)\n",
    "classifier = model_text.named_steps['classifier']\n",
    "vectorizer = model_text.named_steps['vectorizer']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = classifier.coef_[0]\n",
    "\n",
    "word_importance = pd.DataFrame({'word': feature_names, 'coef': coefs})\n",
    "top_positive = word_importance.sort_values(by='coef', ascending=False).head(20)\n",
    "top_negative = word_importance.sort_values(by='coef', ascending=True).head(20)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sns.barplot(ax=axes[0], x='coef', y='word', data=top_positive, palette='Greens_r')\n",
    "axes[0].set_title('Top 20 Palavras: Fatores de Aprovação', fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1], x='coef', y='word', data=top_negative.sort_values(by='coef', ascending=False), palette='Reds_r')\n",
    "axes[1].set_title('Top 20 Palavras: Fatores de Rejeição', fontsize=14)\n",
    "axes[1].invert_xaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização final das Acurácias\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(results.keys()), y=list(results.values()), palette='magma')\n",
    "plt.title('Comparativo de Performance (Acurácia)', fontsize=15)\n",
    "plt.ylim(0.8, 1.0) # Ajuste de escala para melhor visualização\n",
    "for index, value in enumerate(results.values()):\n",
    "    plt.text(index, value + 0.005, f\"{value*100:.2f}%\", ha='center', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório Final de Conclusão\n",
    "\n",
    "#### 1. Metodologia\n",
    "O estudo seguiu um pipeline de Data Science completo, iniciando pela **Análise Exploratória (EDA)** para garantir a qualidade dos dados. Detectou-se que a base estava íntegra (sem nulos), porém a variável `Overall Rating` foi removida por representar um vazamento de dados (alta correlação óbvia com o target). \n",
    "\n",
    "No **pré-processamento**, aplicamos técnicas de NLP (Lematização e remoção de Stopwords) para limpar os textos livres, e transformamos variáveis categóricas em numéricas (One-Hot e Ordinal Encoding) para os metadados.\n",
    "\n",
    "#### 2. Performance dos Modelos\n",
    "Os testes revelaram que o modelo **Híbrido** tende a ser o mais robusto, capturando tanto a subjetividade do texto quanto a objetividade das notas de serviço. No entanto, o modelo puramente textual (**Text**) apresentou desempenho surpreendente, indicando que os clientes expressam suas decisões de recomendação mais fortemente através de palavras-chave do que através de notas isoladas de subcategorias.\n",
    "\n",
    "#### 3. Insights de Negócio\n",
    "A análise de coeficientes da Regressão Logística revelou os direcionadores de satisfação:\n",
    "* **Promotores:** Palavras como *\"excellent\"*, *\"friendly\"*, *\"comfortable\"* e *\"good\"* são os maiores indicativos de uma recomendação positiva.\n",
    "* **Detratores:** A insatisfação é fortemente marcada por termos como *\"dirty\"* (sujeira), *\"rude\"* (grosseria), *\"refund\"* (reembolso) e *\"worst\"* (pior), sugerindo que higiene e atendimento ao cliente são pontos críticos de falha."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
