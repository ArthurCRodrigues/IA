{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final: Análise Híbrida de Satisfação em Companhias Aéreas\n",
    "\n",
    "**Contexto:** Este projeto visa prever a recomendação de passageiros (Sim/Não) utilizando técnicas de Machine Learning.\n",
    "\n",
    "**Estratégia:** Investigaremos se a adição de **dados não estruturados (texto dos reviews)** aos **dados estruturados (notas de serviço)** aumenta a precisão do modelo.\n",
    "\n",
    "**Cenários de Modelagem:**\n",
    "1.  **Tabular:** Random Forest (apenas notas).\n",
    "2.  **Texto (NLP):** Regressão Logística (apenas comentários).\n",
    "3.  **Híbrido:** Random Forest (notas + texto vetorizado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente e Carga de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configurações Visuais\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Correção para download do NLTK (SSL)\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "print(\"Baixando recursos NLTK...\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "print(\"Ambiente pronto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('airlines_reviews.csv')\n",
    "    print(f\"Dados carregados: {df.shape[0]} linhas, {df.shape[1]} colunas.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivo 'airlines_reviews.csv' não encontrado. Faça o upload do dataset.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória (EDA) e Integridade\n",
    "Verificação de nulos, balanceamento de classes e correlações para evitar *Data Leakage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Integridade\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"Diagnóstico: Dataset íntegro (0 nulos).\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# 2. Distribuição do Alvo\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Recommended', data=df, palette='viridis')\n",
    "plt.title('Balanceamento das Classes (Recomendação)', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Matriz de Correlação (Detectando Vazamento de Dados)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlação Numérica', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento e Engenharia de Features\n",
    "Transformação de variáveis categóricas, limpeza de texto (NLP) e remoção de colunas com vazamento de dados (*Overall Rating*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Binário\n",
    "df['target'] = df['Recommended'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Remoção de colunas irrelevantes e 'Overall Rating' (Vazamento de dados)\n",
    "cols_drop = ['Name', 'Title', 'Route', 'Review Date', 'Month Flown', 'Recommended', 'Verified']\n",
    "if 'Overall Rating' in df.columns:\n",
    "    cols_drop.append('Overall Rating')\n",
    "\n",
    "df_clean = df.drop(columns=cols_drop, errors='ignore')\n",
    "\n",
    "# Encoding Ordinal para 'Class'\n",
    "class_map = {'Economy Class': 0, 'Premium Economy': 1, 'Business Class': 2, 'First Class': 3}\n",
    "df_clean['Class_Encoded'] = df_clean['Class'].map(class_map)\n",
    "df_clean.drop('Class', axis=1, inplace=True)\n",
    "\n",
    "# NLP: Limpeza de Texto\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    words = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words and len(w) > 2]\n",
    "    return \" \".join(words)\n",
    "\n",
    "print(\"Processando textos...\")\n",
    "df_clean['Reviews_Clean'] = df_clean['Reviews'].apply(clean_text)\n",
    "print(\"Pré-processamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split de Dados\n",
    "X = df_clean.drop(['target'], axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Treino: {X_train.shape} | Teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelagem e Comparação\n",
    "Treinamento dos três cenários propostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Definição de Features\n",
    "num_feats = ['Seat Comfort', 'Staff Service', 'Food & Beverages', 'Inflight Entertainment', 'Value For Money', 'Class_Encoded']\n",
    "cat_feats = ['Airline', 'Type of Traveller']\n",
    "txt_feat = 'Reviews_Clean'\n",
    "\n",
    "# Transformadores\n",
    "tabular_transformer = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_feats)\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# Modelo 1: Tabular (Random Forest)\n",
    "# ------------------------\n",
    "model_tab = Pipeline([\n",
    "    ('preprocessor', tabular_transformer),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "model_tab.fit(X_train, y_train)\n",
    "acc_tab = accuracy_score(y_test, model_tab.predict(X_test))\n",
    "results['Tabular'] = acc_tab\n",
    "print(f\"Acurácia (Tabular): {acc_tab:.4f}\")\n",
    "\n",
    "# ------------------------\n",
    "# Modelo 2: Texto (Regressão Logística)\n",
    "# ------------------------\n",
    "model_txt = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=3000)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "model_txt.fit(X_train[txt_feat], y_train)\n",
    "acc_txt = accuracy_score(y_test, model_txt.predict(X_test[txt_feat]))\n",
    "results['Texto'] = acc_txt\n",
    "print(f\"Acurácia (Texto): {acc_txt:.4f}\")\n",
    "\n",
    "# ------------------------\n",
    "# Modelo 3: Híbrido\n",
    "# ------------------------\n",
    "hybrid_transformer = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_feats),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_feats),\n",
    "    ('txt', TfidfVectorizer(max_features=3000), txt_feat)\n",
    "])\n",
    "\n",
    "model_hybrid = Pipeline([\n",
    "    ('preprocessor', hybrid_transformer),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "model_hybrid.fit(X_train, y_train)\n",
    "acc_hybrid = accuracy_score(y_test, model_hybrid.predict(X_test))\n",
    "results['Híbrido'] = acc_hybrid\n",
    "print(f\"Acurácia (Híbrido): {acc_hybrid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Resultados e Conclusão\n",
    "Visualização das palavras mais importantes e resumo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Palavras (Baseado na Regressão Logística)\n",
    "feature_names = model_txt.named_steps['vect'].get_feature_names_out()\n",
    "coefs = model_txt.named_steps['clf'].coef_[0]\n",
    "word_imp = pd.DataFrame({'word': feature_names, 'coef': coefs})\n",
    "\n",
    "top_pos = word_imp.sort_values(by='coef', ascending=False).head(15)\n",
    "top_neg = word_imp.sort_values(by='coef', ascending=True).head(15)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.barplot(ax=axes[0], x='coef', y='word', data=top_pos, palette='Greens_r')\n",
    "axes[0].set_title('Top Palavras: RECOMENDA', fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1], x='coef', y='word', data=top_neg.sort_values(by='coef', ascending=False), palette='Reds_r')\n",
    "axes[1].set_title('Top Palavras: NÃO RECOMENDA', fontsize=14)\n",
    "axes[1].invert_xaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico Comparativo Final\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=list(results.keys()), y=list(results.values()), palette='magma')\n",
    "plt.title('Comparativo de Performance (Acurácia)', fontsize=16)\n",
    "plt.ylim(0.8, 1.0)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()*100:.2f}%', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', xytext = (0, 9), textcoords = 'offset points', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório Técnico Final\n",
    "\n",
    "**1. Resumo da Abordagem:**\n",
    "O estudo processou uma base de 8.100 avaliações. Identificamos um vazamento de dados na coluna `Overall Rating` (correlação 0.88), que foi removida. Os dados textuais passaram por limpeza, remoção de *stopwords* e vetorização TF-IDF.\n",
    "\n",
    "**2. Performance dos Modelos:**\n",
    "O comparativo revelou que a inclusão de dados não estruturados (texto) aumentou a capacidade preditiva. O modelo **Híbrido** apresentou a maior robustez, pois combina a objetividade das notas numéricas com as nuances dos relatos livres.\n",
    "\n",
    "**3. Insights de Negócio:**\n",
    "A análise léxica (coeficientes da Regressão Logística) indica que:\n",
    "* **Satisfação** é impulsionada por serviço e conforto (*friendly, excellent, comfortable*).\n",
    "* **Insatisfação** está fortemente ligada a questões financeiras e atendimento (*money, refund, rude, dirty*).\n",
    "\n",
    "**Conclusão:** A mineração de texto provou ser essencial para entender os *porquês* por trás das notas, oferecendo um modelo mais completo para a tomada de decisão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
